{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9186201,"sourceType":"datasetVersion","datasetId":5552874}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tolgaerdogmus/kozmos-sentiment-analysis?scriptVersionId=192905859\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Sentiment Analysis and Sentiment Modeling for Amazon Reviews\n\n## Business Problem\n\nKozmos, a company that produces home textiles and casual wear sold on Amazon, aims to increase its sales by analyzing customer reviews and improving its products based on complaints. To achieve this goal, sentiment analysis will be performed on the reviews, and a classification model will be created using the labeled data.\n\n## Dataset Description\n\nThe dataset consists of variables including product reviews, review titles, star ratings, and the number of people who found the review helpful for a specific product group.\n\n- **Review**: The product review\n- **Title**: The title given to the review content, a short comment\n- **Helpful**: Number of people who found the review helpful\n- **Star**: Number of stars given to the product\n\n## Tasks\n\n### Task 1: Text Preprocessing\n1. Load the amazon.xlsx dataset.\n2. On the \"Review\" variable:\n   a. Convert all letters to lowercase\n   b. Remove punctuation marks\n   c. Remove numerical expressions in the reviews\n   d. Remove stopwords (words that don't contain information)\n   e. Remove words that appear less than 1000 times\n   f. Apply lemmatization\n   Note: Had to take out nltk library due to path issues i seem to not be able to fix yet so Lemmatization is out for now thus Curtain and Curtains are seperated in word cloud.\n\n### Task 2: Text Visualization\n1. Barplot visualization\n   a. Calculate the frequencies of words in the \"Review\" variable, save as tf\n   b. Rename the columns of the tf dataframe to \"words\" and \"tf\"\n   c. Filter for tf values greater than 500 and create a barplot visualization\n\n2. WordCloud visualization\n   a. Save all words in the \"Review\" variable as a string named \"text\"\n   b. Determine and save your template shape using WordCloud\n   c. Generate the wordcloud using the string created in the first step\n   d. Complete the visualization steps (figure, imshow, axis, show)\n\n### Task 3: Sentiment Analysis\n1. Create a SentimentIntensityAnalyzer object from the NLTK package\n2. Examine polarity scores using the SentimentIntensityAnalyzer object\n   a. Calculate polarity_scores() for the first 10 observations of the \"Review\" variable\n   b. Filter and observe the first 10 observations based on compound scores\n   c. Update the 10 observations as \"pos\" if the compound score is greater than 0, otherwise \"neg\"\n   d. Perform pos-neg assignment for all observations in the \"Review\" variable and add as a new variable to the dataframe\n\n### Task 4: Preparation for Machine Learning\n1. Determine dependent and independent variables and split the data into train and test sets\n2. Convert the representation of data to numerical form for the machine learning model\n   a. Create an object using TfidfVectorizer\n   b. Fit the object using the train data\n   c. Apply the transform operation to train and test data using the created vector and save\n\n### Task 5: Modeling (Logistic Regression)\n1. Build a logistic regression model and fit with train data\n2. Perform predictions using the built model\n   a. Predict the test data using the predict function and save\n   b. Report and observe the prediction results using classification_report\n   c. Calculate the average accuracy value using the cross-validation function\n3. Randomly select comments from the data to query the model\n   a. Select a sample from the \"Review\" variable using the sample function and assign to a new value\n   b. Vectorize the sample using CountVectorizer for model prediction\n   c. Fit and transform the vectorized sample and save\n   d. Provide the sample to the model and save the prediction result\n   e. Print the sample and prediction result\n\n### Task 6: Modeling (Random Forest)\n1. Observe prediction results with the Random Forest model\n   a. Build and fit the RandomForestClassifier model\n   b. Calculate the average accuracy value using the cross-validation function\n   c. Compare the results with the logistic regression model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom textblob import TextBlob\nimport re\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-16T19:24:46.131222Z","iopub.execute_input":"2024-08-16T19:24:46.131691Z","iopub.status.idle":"2024-08-16T19:24:46.140044Z","shell.execute_reply.started":"2024-08-16T19:24:46.131643Z","shell.execute_reply":"2024-08-16T19:24:46.138646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Settings\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.2f' % x)\npd.set_option('display.width', 200)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.14206Z","iopub.execute_input":"2024-08-16T19:24:46.142876Z","iopub.status.idle":"2024-08-16T19:24:46.153636Z","shell.execute_reply.started":"2024-08-16T19:24:46.142843Z","shell.execute_reply":"2024-08-16T19:24:46.152513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_excel(\"/kaggle/input/kozmos-amazon-reviews-sentiment-analysis-dataset/amazon.xlsx\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.155014Z","iopub.execute_input":"2024-08-16T19:24:46.155519Z","iopub.status.idle":"2024-08-16T19:24:46.71424Z","shell.execute_reply.started":"2024-08-16T19:24:46.155487Z","shell.execute_reply":"2024-08-16T19:24:46.7131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.717251Z","iopub.execute_input":"2024-08-16T19:24:46.717703Z","iopub.status.idle":"2024-08-16T19:24:46.730316Z","shell.execute_reply.started":"2024-08-16T19:24:46.717662Z","shell.execute_reply":"2024-08-16T19:24:46.729204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define stop words (you can expand this list)\nstop_words = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n                  'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours',\n                  'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she',\n                  \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself',\n                  'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n                  'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am',\n                  'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',\n                  'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the',\n                  'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of',\n                  'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n                  'through', 'during', 'before', 'after', 'above', 'below', 'to',\n                  'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n                  'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where',\n                  'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most',\n                  'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',\n                  'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don',\n                  \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're',\n                  've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n                  \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\",\n                  'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\",\n                  'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n                  \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\",\n                  'wouldn', \"wouldn't\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.731749Z","iopub.execute_input":"2024-08-16T19:24:46.732148Z","iopub.status.idle":"2024-08-16T19:24:46.745902Z","shell.execute_reply.started":"2024-08-16T19:24:46.732111Z","shell.execute_reply":"2024-08-16T19:24:46.744851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove any non-string entries and NaN values\ndf['Review'] = df['Review'].apply(lambda x: str(x) if pd.notna(x) else '')\n# First, calculate the less common words\nsil = pd.Series(' '.join(df['Review']).split()).value_counts()[-1000:]","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.747327Z","iopub.execute_input":"2024-08-16T19:24:46.74773Z","iopub.status.idle":"2024-08-16T19:24:46.814363Z","shell.execute_reply.started":"2024-08-16T19:24:46.747693Z","shell.execute_reply":"2024-08-16T19:24:46.813362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text preprocessing function\ndef preprocess_text(text, remove_rare=True, sil=sil):\n    if pd.isna(text) or text == '':\n        return \"\"\n    \n    # Convert to lowercase\n    text = str(text).lower()\n    \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Remove numbers\n    text = re.sub(r'\\d+', '', text)\n    \n    # Tokenize (simple split)\n    tokens = text.split()\n    \n    # Remove stopwords\n    tokens = [word for word in tokens if word not in stop_words]\n    \n    # Optionally remove less common words\n    if remove_rare:\n        tokens = [word for word in tokens if word not in sil]\n    \n    return ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.815602Z","iopub.execute_input":"2024-08-16T19:24:46.815927Z","iopub.status.idle":"2024-08-16T19:24:46.823069Z","shell.execute_reply.started":"2024-08-16T19:24:46.815894Z","shell.execute_reply":"2024-08-16T19:24:46.822036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing to the 'Review' column\ndf['processed_review'] = df['Review'].apply(preprocess_text, remove_rare=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:46.824242Z","iopub.execute_input":"2024-08-16T19:24:46.824548Z","iopub.status.idle":"2024-08-16T19:24:47.064417Z","shell.execute_reply.started":"2024-08-16T19:24:46.824522Z","shell.execute_reply":"2024-08-16T19:24:47.063256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n# Rarewords / Custom Words\n###############################\n\nsil = pd.Series(' '.join(df['Review']).split()).value_counts()[-1000:]\ndf['Review'] = df['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:47.065778Z","iopub.execute_input":"2024-08-16T19:24:47.066082Z","iopub.status.idle":"2024-08-16T19:24:47.39875Z","shell.execute_reply.started":"2024-08-16T19:24:47.066057Z","shell.execute_reply":"2024-08-16T19:24:47.397782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Review'].head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:47.402927Z","iopub.execute_input":"2024-08-16T19:24:47.403307Z","iopub.status.idle":"2024-08-16T19:24:47.411471Z","shell.execute_reply.started":"2024-08-16T19:24:47.403277Z","shell.execute_reply":"2024-08-16T19:24:47.410498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##############################################################\n# # Text Visualision\n##############################################################\n# Barplot visualization\ntf = pd.DataFrame(df['processed_review'].str.split(expand=True).stack().value_counts())\ntf.columns = ['tf']\ntf = tf[tf['tf'] > 500]\nplt.figure(figsize=(12, 6))\nsns.barplot(x=tf.index, y='tf', data=tf)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:47.412868Z","iopub.execute_input":"2024-08-16T19:24:47.413193Z","iopub.status.idle":"2024-08-16T19:24:47.944135Z","shell.execute_reply.started":"2024-08-16T19:24:47.413154Z","shell.execute_reply":"2024-08-16T19:24:47.943037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n# Wordcloud\n###############################\n# For the WordCloud visualization\ntext = ' '.join(df['processed_review'])\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:47.945699Z","iopub.execute_input":"2024-08-16T19:24:47.946474Z","iopub.status.idle":"2024-08-16T19:24:49.695617Z","shell.execute_reply.started":"2024-08-16T19:24:47.946419Z","shell.execute_reply":"2024-08-16T19:24:49.694471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##############################################################\n# Sentiment Analysis\n##############################################################\ndef get_sentiment(text):\n    return TextBlob(text).sentiment.polarity\n\ndf['sentiment_score'] = df['Review'].apply(get_sentiment)\ndf['sentiment'] = df['sentiment_score'].apply(lambda x: 'pos' if x > 0 else 'neg')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:49.696889Z","iopub.execute_input":"2024-08-16T19:24:49.697229Z","iopub.status.idle":"2024-08-16T19:24:51.516538Z","shell.execute_reply.started":"2024-08-16T19:24:49.697176Z","shell.execute_reply":"2024-08-16T19:24:51.515568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n# Prep before machine learning\n###############################\n# Test-Train\nX = df['processed_review']\ny = df['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:51.518087Z","iopub.execute_input":"2024-08-16T19:24:51.518573Z","iopub.status.idle":"2024-08-16T19:24:51.528386Z","shell.execute_reply.started":"2024-08-16T19:24:51.518538Z","shell.execute_reply":"2024-08-16T19:24:51.527211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TF-IDF Word Level\ntfidf = TfidfVectorizer()\nX_train_tfidf = tfidf.fit_transform(X_train)\nX_test_tfidf = tfidf.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:51.529732Z","iopub.execute_input":"2024-08-16T19:24:51.530069Z","iopub.status.idle":"2024-08-16T19:24:51.638244Z","shell.execute_reply.started":"2024-08-16T19:24:51.530043Z","shell.execute_reply":"2024-08-16T19:24:51.637158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n# Modeling (Lojistik Regresyon)\n###############################\nlr_model = LogisticRegression(random_state=42)\nlr_model.fit(X_train_tfidf, y_train)\n\ny_pred = lr_model.predict(X_test_tfidf)\nprint(\"Logistic Regression Results:\")\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:51.639473Z","iopub.execute_input":"2024-08-16T19:24:51.639898Z","iopub.status.idle":"2024-08-16T19:24:51.768665Z","shell.execute_reply.started":"2024-08-16T19:24:51.639861Z","shell.execute_reply":"2024-08-16T19:24:51.767502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n# Modeling (Random Forest)\n###############################\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_tfidf, y_train)\n\ny_pred_rf = rf_model.predict(X_test_tfidf)\nprint(\"\\nRandom Forest Results:\")\nprint(classification_report(y_test, y_pred_rf))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:51.76988Z","iopub.execute_input":"2024-08-16T19:24:51.770227Z","iopub.status.idle":"2024-08-16T19:24:54.385998Z","shell.execute_reply.started":"2024-08-16T19:24:51.770176Z","shell.execute_reply":"2024-08-16T19:24:54.385011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross-validation\nlr_scores = cross_val_score(lr_model, X_train_tfidf, y_train, cv=5)\nrf_scores = cross_val_score(rf_model, X_train_tfidf, y_train, cv=5)\n\nprint(\"\\nLogistic Regression CV Scores:\", lr_scores)\nprint(\"Logistic Regression Mean CV Score:\", lr_scores.mean())\nprint(\"\\nRandom Forest CV Scores:\", rf_scores)\nprint(\"Random Forest Mean CV Score:\", rf_scores.mean())\n\n# Sample prediction\nsample = df['Review'].sample().iloc[0]\nsample_processed = preprocess_text(sample)\nsample_vector = tfidf.transform([sample_processed])\nlr_prediction = lr_model.predict(sample_vector)[0]\nrf_prediction = rf_model.predict(sample_vector)[0]\n\nprint(\"\\nSample Review:\")\nprint(sample)\nprint(\"\\nLogistic Regression Prediction:\", lr_prediction)\nprint(\"Random Forest Prediction:\", rf_prediction)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T19:24:54.387211Z","iopub.execute_input":"2024-08-16T19:24:54.387529Z","iopub.status.idle":"2024-08-16T19:25:12.714925Z","shell.execute_reply.started":"2024-08-16T19:24:54.387503Z","shell.execute_reply":"2024-08-16T19:25:12.713458Z"},"trusted":true},"execution_count":null,"outputs":[]}]}